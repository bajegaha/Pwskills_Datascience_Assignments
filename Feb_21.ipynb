{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.**\n",
        "<br>\n",
        "Web scraping is the process of extracting data from websites. It involves fetching the web page and then extracting the information you need from the HTML code. Web scraping is used for various purposes, including:<br>\n",
        "\n",
        "<h5><B>Data Collection</B></h5>Web scraping is commonly used to collect data from websites that don't offer APIs or other structured ways to access their data. This could include gathering product prices, stock prices, weather data, or any other information available on websites.\n",
        "\n",
        "<h5><B>Competitor Analysis</B></h5> Businesses use web scraping to monitor and analyze their competitors' activities, pricing strategies, and product offerings. This helps them make informed decisions and stay competitive in the market.\n",
        "\n",
        "<h5><B>Research and Analysis</h5></B> Researchers use web scraping to gather data for academic or market research. It allows them to analyze trends, sentiment, and other relevant information from various sources on the internet.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BVCQHcAnkdAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "**Q2. What are the different methods used for Web Scraping?**\n",
        "\n",
        "There are several methods for web scraping, including:\n",
        "\n",
        "<h5><B>Manual Copy-Pasting</h5></B> This involves manually copying and pasting data from websites to a local file or spreadsheet.\n",
        "\n",
        "<h5><B>Using Web Scraping Tools<h5/></B> Various tools and software are available that simplify the web scraping process. These tools often provide a graphical interface to select and extract data from websites.\n",
        "\n",
        "<h5><B>Programming with Libraries</h5></B>Many programming languages, such as Python, provide libraries specifically designed for web scraping. Some popular ones include BeautifulSoup and Scrapy for Python.\n",
        "\n",
        "<h5><B>Browser Extensions</h5></B> There are browser extensions like Chrome's Data Miner that allow users to scrape data from websites using a browser interface.\n"
      ],
      "metadata": {
        "id": "oeVPpPH7kdDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><B>Q3.What is Beautiful Soup? Why is it used? </B>\n",
        "\n",
        "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates parse trees that can be used to extract data easily. It's particularly helpful in web scraping because it allows you to navigate and search through the HTML structure of a webpage, making it simpler to extract specific data."
      ],
      "metadata": {
        "id": "GcRzznB-kdF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>**Q4. Why is Flask used in this Web Scraping project?**\n",
        "\n",
        "Flask is a web framework in Python used for building web applications. In a web scraping project, Flask can be used to create a web interface that allows users to interact with the scraped data. For instance, it can display the extracted data in a user-friendly format or provide a means for users to input parameters for the scraping process."
      ],
      "metadata": {
        "id": "MC235l7jkdIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><B>Q5. Write the names of AWS services used in this project. Also, explain the use of each service.</B><br>\n",
        "AWS (Amazon Web Services) offers various services that could be used in a web scraping project:\n",
        "\n",
        "<h5>EC2 (Elastic Compute Cloud): Provides resizable compute capacity in the cloud, often used to host the web scraping scripts or applications.\n",
        "<h5>S3 (Simple Storage Service): Used for storing scraped data or any other files, providing scalable object storage.\n",
        "<h5>Lambda: Could be used for serverless computing, where functions can be executed in response to certain events (like triggering a scraping job).\n",
        "<h5>CloudWatch: Offers monitoring and logging services, allowing you to monitor the performance of your scraping processes.\n",
        "<h5>IAM (Identity and Access Management): Manages access to AWS services, ensuring security by controlling who can access specific resources."
      ],
      "metadata": {
        "id": "tq1Wib7okdKZ"
      }
    }
  ]
}